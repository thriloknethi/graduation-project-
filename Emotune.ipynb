{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IapAs2VD-Vk-",
        "outputId": "e2a6ef95-755c-461a-ed26-97d4bcec15be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Collecting spotipy\n",
            "  Downloading spotipy-2.25.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Collecting redis>=3.5.3 (from spotipy)\n",
            "  Downloading redis-5.2.1-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from spotipy) (2.2.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis>=3.5.3->spotipy) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Downloading spotipy-2.25.0-py3-none-any.whl (30 kB)\n",
            "Downloading redis-5.2.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m261.5/261.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: redis, spotipy\n",
            "Successfully installed redis-5.2.1 spotipy-2.25.0\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow opencv-python spotipy numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "import requests\n",
        "from collections import defaultdict\n",
        "import random\n",
        "import time\n",
        "\n",
        "def js_to_image(js_reply):\n",
        "    \"\"\"Convert JS image capture to OpenCV format\"\"\"\n",
        "    image_bytes = b64decode(js_reply.split(',')[1])\n",
        "    jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "    img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "    return img\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "    \"\"\"Capture photo from webcam\"\"\"\n",
        "    js = Javascript('''\n",
        "        async function takePhoto(quality) {\n",
        "            const div = document.createElement('div');\n",
        "            const capture = document.createElement('button');\n",
        "            capture.textContent = 'Capture';\n",
        "            div.appendChild(capture);\n",
        "\n",
        "            const video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "            document.body.appendChild(div);\n",
        "            div.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "            await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            div.remove();\n",
        "            return canvas.toDataURL('image/jpeg', quality);\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    return js_to_image(data)\n",
        "\n",
        "class EmotionMusicRecommender:\n",
        "    def __init__(self, lastfm_api_key):\n",
        "        print(\"Initializing EmotionMusicRecommender...\")\n",
        "\n",
        "        # Initialize emotion model\n",
        "        print(\"Loading emotion detection model...\")\n",
        "        self.emotion_model = self._build_emotion_model()\n",
        "\n",
        "        # Initialize Last.fm\n",
        "        print(\"Setting up Last.fm API...\")\n",
        "        self.lastfm_api_key = lastfm_api_key\n",
        "        self.lastfm_base_url = \"http://ws.audioscrobbler.com/2.0/\"\n",
        "\n",
        "        # Test Last.fm connection\n",
        "        try:\n",
        "            self._make_lastfm_request(method=\"chart.getTopArtists\", limit=1)\n",
        "            print(\"âœ… Last.fm connection verified!\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Last.fm connection error: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "        # Emotion mappings with Last.fm tags\n",
        "        self.emotion_tags = {\n",
        "            'happy': ['happy', 'upbeat', 'fun', 'party', 'energetic'],\n",
        "            'sad': ['sad', 'melancholic', 'slow', 'emotional', 'ballad'],\n",
        "            'angry': ['angry', 'aggressive', 'metal', 'intense', 'hardcore'],\n",
        "            'neutral': ['chill', 'relaxing', 'ambient', 'smooth', 'easy'],\n",
        "            'surprised': ['upbeat', 'electronic', 'dance', 'exciting', 'energetic'],\n",
        "            'fearful': ['dark', 'atmospheric', 'intense', 'dramatic', 'epic'],\n",
        "            'disgusted': ['intense', 'aggressive', 'dark', 'heavy', 'experimental']\n",
        "        }\n",
        "\n",
        "        self.recommendation_cache = defaultdict(list)\n",
        "        print(\"Initialization complete! âœ¨\")\n",
        "\n",
        "    def _build_emotion_model(self):\n",
        "        \"\"\"Build emotion detection model\"\"\"\n",
        "        base_model = MobileNetV2(\n",
        "            weights='imagenet',\n",
        "            include_top=False,\n",
        "            input_shape=(224, 224, 3)\n",
        "        )\n",
        "        base_model.trainable = False\n",
        "\n",
        "        model = Sequential([\n",
        "            base_model,\n",
        "            Conv2D(64, (3, 3), activation='relu'),\n",
        "            MaxPooling2D(2, 2),\n",
        "            Dropout(0.25),\n",
        "            Flatten(),\n",
        "            Dense(128, activation='relu'),\n",
        "            Dropout(0.5),\n",
        "            Dense(7, activation='softmax')\n",
        "        ])\n",
        "\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def _make_lastfm_request(self, method, **params):\n",
        "        \"\"\"Make a request to Last.fm API\"\"\"\n",
        "        params.update({\n",
        "            'method': method,\n",
        "            'api_key': self.lastfm_api_key,\n",
        "            'format': 'json'\n",
        "        })\n",
        "\n",
        "        response = requests.get(self.lastfm_base_url, params=params)\n",
        "        response.raise_for_status()\n",
        "        return response.json()\n",
        "\n",
        "    def detect_emotion(self, frame):\n",
        "        \"\"\"Detect emotion from video frame\"\"\"\n",
        "        face_cascade = cv2.CascadeClassifier(\n",
        "            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
        "        )\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "        if len(faces) == 0:\n",
        "            return None\n",
        "\n",
        "        (x, y, w, h) = max(faces, key=lambda face: face[2] * face[3])\n",
        "        face_roi = frame[y:y+h, x:x+w]\n",
        "        face_roi = cv2.resize(face_roi, (224, 224))\n",
        "        face_roi = tf.keras.applications.mobilenet_v2.preprocess_input(\n",
        "            np.expand_dims(face_roi, axis=0)\n",
        "        )\n",
        "\n",
        "        emotions = ['angry', 'disgusted', 'fearful', 'happy', 'neutral', 'sad', 'surprised']\n",
        "        prediction = self.emotion_model.predict(face_roi, verbose=0)\n",
        "        emotion = emotions[np.argmax(prediction)]\n",
        "        confidence = np.max(prediction)\n",
        "\n",
        "        return {'emotion': emotion, 'confidence': confidence}\n",
        "\n",
        "    def get_music_recommendations(self, emotion, limit=5):\n",
        "        \"\"\"Get music recommendations based on emotion using Last.fm\"\"\"\n",
        "        try:\n",
        "            print(f\"\\nğŸµ Finding {emotion} music...\")\n",
        "\n",
        "            # Get random tags for this emotion\n",
        "            tags = random.sample(self.emotion_tags[emotion], 2)\n",
        "            tag_string = \",\".join(tags)\n",
        "            print(f\"Using tags: {tag_string}\")\n",
        "\n",
        "            # Get tag-based recommendations\n",
        "            results = self._make_lastfm_request(\n",
        "                method=\"tag.getTopTracks\",\n",
        "                tag=random.choice(tags),\n",
        "                limit=limit\n",
        "            )\n",
        "\n",
        "            # Format recommendations\n",
        "            recommendations = []\n",
        "            for track in results['tracks']['track']:\n",
        "                recommendations.append({\n",
        "                    'name': track['name'],\n",
        "                    'artist': track['artist']['name'],\n",
        "                    'url': track['url']\n",
        "                })\n",
        "\n",
        "            return recommendations\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nâš ï¸ Error getting recommendations: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def run_emotion_detection(self):\n",
        "        \"\"\"Main loop for emotion detection and music recommendation\"\"\"\n",
        "        print(\"\\nğŸµ Welcome to Emotion-Based Music Recommender! ğŸµ\")\n",
        "        print(\"Each photo will analyze your emotion and suggest music to match.\")\n",
        "\n",
        "        try:\n",
        "            while True:\n",
        "                print(\"\\nğŸ“¸ Capturing image... Click 'Capture' when ready!\")\n",
        "                frame = take_photo()\n",
        "\n",
        "                print(\"\\nğŸ” Analyzing emotion...\")\n",
        "                emotion_result = self.detect_emotion(frame)\n",
        "\n",
        "                if emotion_result:\n",
        "                    emotion = emotion_result['emotion']\n",
        "                    confidence = emotion_result['confidence']\n",
        "\n",
        "                    print(f\"\\nğŸ˜Š Detected emotion: {emotion.upper()} (confidence: {confidence:.2f})\")\n",
        "\n",
        "                    if confidence > 0.4:\n",
        "                        recommendations = self.get_music_recommendations(emotion)\n",
        "\n",
        "                        if recommendations:\n",
        "                            print(\"\\nğŸ§ Recommended songs based on your emotion:\")\n",
        "                            for i, rec in enumerate(recommendations, 1):\n",
        "                                print(f\"\\n{i}. {rec['name']} by {rec['artist']}\")\n",
        "                                print(f\"   ğŸ”— Listen on Last.fm: {rec['url']}\")\n",
        "                        else:\n",
        "                            print(\"\\nâŒ Could not find recommendations. Trying again...\")\n",
        "                            # Second attempt with different tags\n",
        "                            time.sleep(1)  # Add delay to avoid rate limiting\n",
        "                            recommendations = self.get_music_recommendations(emotion)\n",
        "                            if recommendations:\n",
        "                                print(\"\\nğŸ§ Second attempt - Recommended songs:\")\n",
        "                                for i, rec in enumerate(recommendations, 1):\n",
        "                                    print(f\"\\n{i}. {rec['name']} by {rec['artist']}\")\n",
        "                                    print(f\"   ğŸ”— Listen on Last.fm: {rec['url']}\")\n",
        "                            else:\n",
        "                                print(\"\\nâŒ Still no recommendations found. Please try another photo.\")\n",
        "                    else:\n",
        "                        print(\"\\nâš ï¸ Low confidence in emotion detection. Please try another photo.\")\n",
        "                else:\n",
        "                    print(\"\\nâŒ No face detected. Please ensure your face is clearly visible!\")\n",
        "\n",
        "                user_input = input(\"\\nğŸ“¸ Press Enter to capture another photo or 'q' to quit: \")\n",
        "                if user_input.lower() == 'q':\n",
        "                    break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nâŒ An error occurred: {str(e)}\")\n",
        "            print(\"Error details:\", str(e))\n",
        "\n",
        "        print(\"\\nğŸ‘‹ Thank you for using Emotion-Based Music Recommender!\")\n",
        "\n",
        "# Your Last.fm API key\n",
        "LASTFM_API_KEY = \"a6eb8040a05bc20040d9d733a01590c4\"  # Replace with your Last.fm API key\n",
        "\n",
        "# Create and run the recommender\n",
        "recommender = EmotionMusicRecommender(LASTFM_API_KEY)\n",
        "recommender.run_emotion_detection()"
      ],
      "metadata": {
        "id": "V2odDi5x-h-L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "outputId": "42da2634-c0e5-4c7e-daf5-51dc4d22e5e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing EmotionMusicRecommender...\n",
            "Loading emotion detection model...\n",
            "Setting up Last.fm API...\n",
            "âœ… Last.fm connection verified!\n",
            "Initialization complete! âœ¨\n",
            "\n",
            "ğŸµ Welcome to Emotion-Based Music Recommender! ğŸµ\n",
            "Each photo will analyze your emotion and suggest music to match.\n",
            "\n",
            "ğŸ“¸ Capturing image... Click 'Capture' when ready!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const capture = document.createElement('button');\n",
              "            capture.textContent = 'Capture';\n",
              "            div.appendChild(capture);\n",
              "\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "\n",
              "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "            await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ” Analyzing emotion...\n",
            "\n",
            "ğŸ˜Š Detected emotion: HAPPY (confidence: 0.51)\n",
            "\n",
            "ğŸµ Finding happy music...\n",
            "Using tags: party,fun\n",
            "\n",
            "ğŸ§ Recommended songs based on your emotion:\n",
            "\n",
            "1. Hey Ya! by OutKast\n",
            "   ğŸ”— Listen on Last.fm: https://www.last.fm/music/OutKast/_/Hey+Ya%21\n",
            "\n",
            "2. Last Friday Night (T.G.I.F.) by Katy Perry\n",
            "   ğŸ”— Listen on Last.fm: https://www.last.fm/music/Katy+Perry/_/Last+Friday+Night+(T.G.I.F.)\n",
            "\n",
            "3. A-Punk by Vampire Weekend\n",
            "   ğŸ”— Listen on Last.fm: https://www.last.fm/music/Vampire+Weekend/_/A-Punk\n",
            "\n",
            "4. espresso by Sabrina Carpenter\n",
            "   ğŸ”— Listen on Last.fm: https://www.last.fm/music/Sabrina+Carpenter/_/espresso\n",
            "\n",
            "5. We Are Young (feat. Janelle MonÃ¡e) by fun.\n",
            "   ğŸ”— Listen on Last.fm: https://www.last.fm/music/fun./_/We+Are+Young+(feat.+Janelle+Mon%C3%A1e)\n",
            "\n",
            "ğŸ“¸ Press Enter to capture another photo or 'q' to quit: q\n",
            "\n",
            "ğŸ‘‹ Thank you for using Emotion-Based Music Recommender!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ytmusicapi"
      ],
      "metadata": {
        "id": "0Uwi8lKolc1v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "effe8f54-3db2-482a-9bd5-dac0abfe3041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ytmusicapi\n",
            "  Downloading ytmusicapi-1.9.1-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: requests>=2.22 in /usr/local/lib/python3.10/dist-packages (from ytmusicapi) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22->ytmusicapi) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22->ytmusicapi) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22->ytmusicapi) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22->ytmusicapi) (2024.12.14)\n",
            "Downloading ytmusicapi-1.9.1-py3-none-any.whl (92 kB)\n",
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/92.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”\u001b[0m \u001b[32m81.9/92.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ytmusicapi\n",
            "Successfully installed ytmusicapi-1.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from ytmusicapi import YTMusic\n",
        "from collections import defaultdict\n",
        "import random\n",
        "import time\n",
        "\n",
        "def js_to_image(js_reply):\n",
        "    \"\"\"Convert JS image capture to OpenCV format\"\"\"\n",
        "    image_bytes = b64decode(js_reply.split(',')[1])\n",
        "    jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "    img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "    return img\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "    \"\"\"Capture photo from webcam\"\"\"\n",
        "    js = Javascript('''\n",
        "        async function takePhoto(quality) {\n",
        "            const div = document.createElement('div');\n",
        "            const capture = document.createElement('button');\n",
        "            capture.textContent = 'Capture';\n",
        "            div.appendChild(capture);\n",
        "\n",
        "            const video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "            document.body.appendChild(div);\n",
        "            div.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "            await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            div.remove();\n",
        "            return canvas.toDataURL('image/jpeg', quality);\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    return js_to_image(data)\n",
        "\n",
        "class EmotionMusicRecommender:\n",
        "    def __init__(self):\n",
        "        print(\"Initializing EmotionMusicRecommender...\")\n",
        "\n",
        "        # Initialize emotion model\n",
        "        print(\"Loading emotion detection model...\")\n",
        "        self.emotion_model = self._build_emotion_model()\n",
        "\n",
        "        # Initialize YouTube Music\n",
        "        print(\"Setting up YouTube Music API...\")\n",
        "        self.ytmusic = YTMusic()\n",
        "\n",
        "        # Test YouTube Music connection\n",
        "        try:\n",
        "            self.ytmusic.search(\"test\", filter=\"songs\", limit=1)\n",
        "            print(\"âœ… YouTube Music connection verified!\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ YouTube Music connection error: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "        # Emotion mappings with Indian music keywords\n",
        "        self.emotion_keywords = {\n",
        "            'happy': [\n",
        "                'happy bollywood songs', 'upbeat hindi songs',\n",
        "                'punjabi bhangra songs', 'celebration hindi songs',\n",
        "                'dance bollywood hits'\n",
        "            ],\n",
        "            'sad': [\n",
        "                'sad hindi songs', 'emotional bollywood songs',\n",
        "                'hindi sad love songs', 'emotional ghazals',\n",
        "                'heartbreak bollywood songs','telugu sad love songs'\n",
        "            ],\n",
        "            'angry': [\n",
        "                'powerful bollywood songs', 'aggressive hindi songs',\n",
        "                'rock hindi songs', 'intense bollywood songs',\n",
        "                'motivational hindi songs'\n",
        "            ],\n",
        "            'neutral': [\n",
        "                'peaceful hindi songs', 'relaxing bollywood songs',\n",
        "                'meditation indian music', 'soft hindi songs',\n",
        "                'soothing bollywood music'\n",
        "            ],\n",
        "            'surprised': [\n",
        "                'energetic bollywood songs', 'fusion indian songs',\n",
        "                'modern hindi songs', 'trending bollywood hits',\n",
        "                'new bollywood remixes'\n",
        "            ],\n",
        "            'fearful': [\n",
        "                'dramatic bollywood songs', 'suspense hindi songs',\n",
        "                'thriller bollywood music', 'intense indian songs',\n",
        "                'dark mood bollywood'\n",
        "            ],\n",
        "            'disgusted': [\n",
        "                'intense bollywood songs', 'powerful hindi songs',\n",
        "                'strong bollywood tracks', 'dark mood hindi songs',\n",
        "                'dramatic indian music'\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        self.recommendation_cache = defaultdict(list)\n",
        "        print(\"Initialization complete! âœ¨\")\n",
        "\n",
        "    def _build_emotion_model(self):\n",
        "        \"\"\"Build emotion detection model\"\"\"\n",
        "        base_model = MobileNetV2(\n",
        "            weights='imagenet',\n",
        "            include_top=False,\n",
        "            input_shape=(224, 224, 3)\n",
        "        )\n",
        "        base_model.trainable = False\n",
        "\n",
        "        model = Sequential([\n",
        "            base_model,\n",
        "            Conv2D(64, (3, 3), activation='relu'),\n",
        "            MaxPooling2D(2, 2),\n",
        "            Dropout(0.25),\n",
        "            Flatten(),\n",
        "            Dense(128, activation='relu'),\n",
        "            Dropout(0.5),\n",
        "            Dense(7, activation='softmax')\n",
        "        ])\n",
        "\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def detect_emotion(self, frame):\n",
        "        \"\"\"Detect emotion from video frame\"\"\"\n",
        "        face_cascade = cv2.CascadeClassifier(\n",
        "            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
        "        )\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "        if len(faces) == 0:\n",
        "            return None\n",
        "\n",
        "        (x, y, w, h) = max(faces, key=lambda face: face[2] * face[3])\n",
        "        face_roi = frame[y:y+h, x:x+w]\n",
        "        face_roi = cv2.resize(face_roi, (224, 224))\n",
        "        face_roi = tf.keras.applications.mobilenet_v2.preprocess_input(\n",
        "            np.expand_dims(face_roi, axis=0)\n",
        "        )\n",
        "\n",
        "        emotions = ['angry', 'disgusted', 'fearful', 'happy', 'neutral', 'sad', 'surprised']\n",
        "        prediction = self.emotion_model.predict(face_roi, verbose=0)\n",
        "        emotion = emotions[np.argmax(prediction)]\n",
        "        confidence = np.max(prediction)\n",
        "\n",
        "        return {'emotion': emotion, 'confidence': confidence}\n",
        "\n",
        "    def get_music_recommendations(self, emotion, limit=5):\n",
        "        \"\"\"Get Indian music recommendations based on emotion using YouTube Music\"\"\"\n",
        "        try:\n",
        "            print(f\"\\nğŸµ Finding {emotion} Indian music...\")\n",
        "\n",
        "            # Get random keywords for this emotion\n",
        "            search_query = random.choice(self.emotion_keywords[emotion])\n",
        "            print(f\"Using search query: {search_query}\")\n",
        "\n",
        "            # Search for songs\n",
        "            results = self.ytmusic.search(search_query, filter=\"songs\", limit=limit)\n",
        "\n",
        "            # Format recommendations\n",
        "            recommendations = []\n",
        "            for song in results:\n",
        "                if song.get('resultType') == 'song':\n",
        "                    recommendations.append({\n",
        "                        'name': song.get('title', ''),\n",
        "                        'artist': ', '.join([artist['name'] for artist in song.get('artists', [])]),\n",
        "                        'album': song.get('album', {}).get('name', ''),\n",
        "                        'duration': song.get('duration', ''),\n",
        "                        'url': f\"https://music.youtube.com/watch?v={song.get('videoId')}\"\n",
        "                    })\n",
        "\n",
        "            return recommendations[:limit]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nâš ï¸ Error getting recommendations: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def run_emotion_detection(self):\n",
        "        \"\"\"Main loop for emotion detection and music recommendation\"\"\"\n",
        "        print(\"\\nğŸµ Welcome to Indian Music Emotion Recommender! ğŸµ\")\n",
        "        print(\"Each photo will analyze your emotion and suggest Indian songs to match.\")\n",
        "\n",
        "        try:\n",
        "            while True:\n",
        "                print(\"\\nğŸ“¸ Capturing image... Click 'Capture' when ready!\")\n",
        "                frame = take_photo()\n",
        "\n",
        "                print(\"\\nğŸ” Analyzing emotion...\")\n",
        "                emotion_result = self.detect_emotion(frame)\n",
        "\n",
        "                if emotion_result:\n",
        "                    emotion = emotion_result['emotion']\n",
        "                    confidence = emotion_result['confidence']\n",
        "\n",
        "                    print(f\"\\nğŸ˜Š Detected emotion: {emotion.upper()} (confidence: {confidence:.2f})\")\n",
        "\n",
        "                    if confidence > 0.4:\n",
        "                        recommendations = self.get_music_recommendations(emotion)\n",
        "\n",
        "                        if recommendations:\n",
        "                            print(\"\\nğŸ§ Recommended Indian songs based on your emotion:\")\n",
        "                            for i, rec in enumerate(recommendations, 1):\n",
        "                                print(f\"\\n{i}. {rec['name']}\")\n",
        "                                print(f\"   ğŸ‘¤ Artist: {rec['artist']}\")\n",
        "                                print(f\"   ğŸ’¿ Album: {rec['album']}\")\n",
        "                                print(f\"   â±ï¸ Duration: {rec['duration']}\")\n",
        "                                print(f\"   ğŸ”— Listen: {rec['url']}\")\n",
        "                        else:\n",
        "                            print(\"\\nâŒ Could not find recommendations. Trying again...\")\n",
        "                            # Second attempt with different keywords\n",
        "                            time.sleep(1)  # Add delay to avoid rate limiting\n",
        "                            recommendations = self.get_music_recommendations(emotion)\n",
        "                            if recommendations:\n",
        "                                print(\"\\nğŸ§ Second attempt - Recommended songs:\")\n",
        "                                for i, rec in enumerate(recommendations, 1):\n",
        "                                    print(f\"\\n{i}. {rec['name']}\")\n",
        "                                    print(f\"   ğŸ‘¤ Artist: {rec['artist']}\")\n",
        "                                    print(f\"   ğŸ’¿ Album: {rec['album']}\")\n",
        "                                    print(f\"   â±ï¸ Duration: {rec['duration']}\")\n",
        "                                    print(f\"   ğŸ”— Listen: {rec['url']}\")\n",
        "                            else:\n",
        "                                print(\"\\nâŒ Still no recommendations found. Please try another photo.\")\n",
        "                    else:\n",
        "                        print(\"\\nâš ï¸ Low confidence in emotion detection. Please try another photo.\")\n",
        "                else:\n",
        "                    print(\"\\nâŒ No face detected. Please ensure your face is clearly visible!\")\n",
        "\n",
        "                user_input = input(\"\\nğŸ“¸ Press Enter to capture another photo or 'q' to quit: \")\n",
        "                if user_input.lower() == 'q':\n",
        "                    break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nâŒ An error occurred: {str(e)}\")\n",
        "            print(\"Error details:\", str(e))\n",
        "\n",
        "        print(\"\\nğŸ‘‹ Thank you for using Indian Music Emotion Recommender!\")\n",
        "\n",
        "# First install the required package\n",
        "\n",
        "\n",
        "# Create and run the recommender\n",
        "recommender = EmotionMusicRecommender()\n",
        "recommender.run_emotion_detection()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "id": "tXyvnzAN2bXi",
        "outputId": "3035747a-6789-4e06-c0a8-c41cd68cad35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing EmotionMusicRecommender...\n",
            "Loading emotion detection model...\n",
            "Setting up YouTube Music API...\n",
            "âœ… YouTube Music connection verified!\n",
            "Initialization complete! âœ¨\n",
            "\n",
            "ğŸµ Welcome to Indian Music Emotion Recommender! ğŸµ\n",
            "Each photo will analyze your emotion and suggest Indian songs to match.\n",
            "\n",
            "ğŸ“¸ Capturing image... Click 'Capture' when ready!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const capture = document.createElement('button');\n",
              "            capture.textContent = 'Capture';\n",
              "            div.appendChild(capture);\n",
              "\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "\n",
              "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "            await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ” Analyzing emotion...\n",
            "\n",
            "ğŸ˜Š Detected emotion: SURPRISED (confidence: 0.48)\n",
            "\n",
            "ğŸµ Finding surprised Indian music...\n",
            "Using search query: fusion indian songs\n",
            "\n",
            "ğŸ§ Recommended Indian songs based on your emotion:\n",
            "\n",
            "1. Indian Flute Music: Instrumental Meditation Music, Yoga Spa Music and Relaxation\n",
            "   ğŸ‘¤ Artist: Nature Sounds\n",
            "   ğŸ’¿ Album: Indian Flute Music: Instrumental Meditation Music, Yoga Spa Music and Relaxation\n",
            "   â±ï¸ Duration: 1:57:59\n",
            "   ğŸ”— Listen: https://music.youtube.com/watch?v=5F_lxaJkXUM\n",
            "\n",
            "2. Divine Indian Flute Music\n",
            "   ğŸ‘¤ Artist: Supernatural Brainwave Power\n",
            "   ğŸ’¿ Album: Manifestation Sutra\n",
            "   â±ï¸ Duration: 1:00:26\n",
            "   ğŸ”— Listen: https://music.youtube.com/watch?v=91iGTV2HNbY\n",
            "\n",
            "3. Tantra Flute (Indian Flute Meditation Music)\n",
            "   ğŸ‘¤ Artist: Meditative Mind\n",
            "   ğŸ’¿ Album: Tantra Flute (Indian Flute Meditation Music)\n",
            "   â±ï¸ Duration: 1:01:01\n",
            "   ğŸ”— Listen: https://music.youtube.com/watch?v=FUg-f_2S-ro\n",
            "\n",
            "4. Bollywood Dj Non Stop Remix(Remix By Dj Jitesh,Psynth)\n",
            "   ğŸ‘¤ Artist: Bappi Lahiri, K.K., Anushka Manchanda, Kamal Khan, Aishwarya, Hrithik Roshan, Diljit, Farhan Akhtar, Keerthi Sagathia, Abhishek Nainwal, Abhay Deol, Amrita Kak, Bob, Akon, Shreya Ghoshal, Earl Edgar D, Hamsika Iyer, Arijit, and Javed Ali\n",
            "   ğŸ’¿ Album: Bollywood Dj\n",
            "   â±ï¸ Duration: 50:23\n",
            "   ğŸ”— Listen: https://music.youtube.com/watch?v=68RLvhxk_4g\n",
            "\n",
            "5. A Fusion In Raag Des\n",
            "   ğŸ‘¤ Artist: Paras Nath\n",
            "   ğŸ’¿ Album: World Fusion Flautist Paras Nath\n",
            "   â±ï¸ Duration: 6:49\n",
            "   ğŸ”— Listen: https://music.youtube.com/watch?v=1c5mWmBRAqE\n",
            "\n",
            "ğŸ“¸ Press Enter to capture another photo or 'q' to quit: q\n",
            "\n",
            "ğŸ‘‹ Thank you for using Indian Music Emotion Recommender!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "var="
      ],
      "metadata": {
        "id": "9KLWWXW53Olj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ikJu6MJb4L3O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}